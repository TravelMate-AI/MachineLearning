{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO4u-s_M2ceX",
        "outputId": "f002bf74-735a-4e78-a17c-57f1e52c8e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, TFAutoModel"
      ],
      "metadata": {
        "id": "PYRUgN7QyZLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data_hotel.csv\")\n",
        "df['Description'] = df['Description'].str.lower()\n",
        "print(\"Dataset info:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdBVJDbByeVt",
        "outputId": "71ccdb46-62ca-4c79-ea08-801d573df243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 90 entries, 0 to 89\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Name         90 non-null     object\n",
            " 1   Description  90 non-null     object\n",
            " 2   Lokasi       88 non-null     object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare tokenizer and pretrained IndoBERT model (TensorFlow)\n",
        "model_name = \"indobenchmark/indobert-base-p2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = TFAutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-PbhwXbygll",
        "outputId": "e9fe01b0-610f-44ae-e46c-9fd1ed0cba53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at indobenchmark/indobert-base-p2 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at indobenchmark/indobert-base-p2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Generate embeddings from text - returns numpy array (1, hidden_size)\n",
        "def get_bert_embeddings(texts):\n",
        "    # texts: list of strings or single string\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    inputs = tokenizer(texts, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
        "    outputs = bert_model(inputs)\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "    return embeddings.numpy()"
      ],
      "metadata": {
        "id": "9WvGl7hFyi1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prepare Training Data for Keras model\n",
        "# Generate embeddings for all hotel descriptions\n",
        "hotel_desc_embeddings = get_bert_embeddings(df['Description'].tolist())\n",
        "\n",
        "# Encode hotel names as class labels for classification task\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(df['Name'])\n",
        "\n",
        "# Re-encode labels after combining rare classes\n",
        "labels = label_encoder.fit_transform(df['Name'])\n",
        "\n",
        "# Generate embeddings again after modifying the dataset\n",
        "hotel_desc_embeddings = get_bert_embeddings(df['Description'].tolist())\n",
        "\n",
        "# Split into train and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(hotel_desc_embeddings, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eccMAxdWyyDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Build tunable keras model function for hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    inputs = tf.keras.Input(shape=(hotel_desc_embeddings.shape[1],))\n",
        "    x = inputs\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        units = hp.Int(f'units_{i}', min_value=64, max_value=512, step=64)\n",
        "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
        "        dropout_rate = hp.Float(f'dropout_{i}', 0.1, 0.5, step=0.1)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pdu13q3iy1vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Run hyperparameter tuning with Keras Tuner Hyperband\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='kt_tuner_dir',\n",
        "    project_name='hotel_nlp_recommendation'\n",
        ")\n",
        "\n",
        "# Early stopping callback to reduce overfitting\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "print(\"Starting hyperparameter search...\")\n",
        "tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[stop_early])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(f\"Number of layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Layer {i} units: {best_hps.get(f'units_{i}')}, dropout: {best_hps.get(f'dropout_{i}')}\")\n",
        "\n",
        "print(f\"Learning rate: {best_hps.get('learning_rate')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0ebrsmXy4cR",
        "outputId": "b855bb44-392d-41df-c332-ae33492a7ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from kt_tuner_dir/hotel_nlp_recommendation/tuner0.json\n",
            "Starting hyperparameter search...\n",
            "Best hyperparameters found:\n",
            "Number of layers: 2\n",
            "Layer 0 units: 512, dropout: 0.5\n",
            "Layer 1 units: 64, dropout: 0.1\n",
            "Learning rate: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Build the best model and train fully\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[stop_early]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUyozk5my7IL",
        "outputId": "47069517-3533-44f4-8285-a093bb1ce4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.0109 - loss: 4.9049 - val_accuracy: 0.0556 - val_loss: 4.7097\n",
            "Epoch 2/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 4.8556 - val_accuracy: 0.0556 - val_loss: 4.7460\n",
            "Epoch 3/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.0109 - loss: 4.7994 - val_accuracy: 0.0556 - val_loss: 4.7810\n",
            "Epoch 4/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.0069 - loss: 4.6832 - val_accuracy: 0.0000e+00 - val_loss: 4.8232\n",
            "Epoch 5/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.0109 - loss: 4.5706 - val_accuracy: 0.0000e+00 - val_loss: 4.8532\n",
            "Epoch 6/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0443 - loss: 4.4896 - val_accuracy: 0.0000e+00 - val_loss: 4.8617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Helper function to recommend hotels based on similarity of embeddings refined by trained Keras model\n",
        "def recommend_hotels(user_prompt, location, top_n=5):\n",
        "    user_embedding = get_bert_embeddings(user_prompt)\n",
        "    intermediate_layer_model = tf.keras.Model(\n",
        "        inputs=model.input,\n",
        "        outputs=model.layers[-2].output\n",
        "    )\n",
        "    user_refined_embedding = intermediate_layer_model(user_embedding).numpy()\n",
        "\n",
        "    filtered_df = df[df['Lokasi'].str.lower() == location.lower()]\n",
        "    filtered_embeddings = []\n",
        "    filtered_names = []\n",
        "    for idx, row in filtered_df.iterrows():\n",
        "        emb = hotel_desc_embeddings[idx:idx+1]\n",
        "        refined_emb = intermediate_layer_model(emb).numpy()\n",
        "        filtered_embeddings.append(refined_emb[0])\n",
        "        filtered_names.append(row['Name'])\n",
        "\n",
        "    filtered_embeddings = np.array(filtered_embeddings)\n",
        "    user_vec = user_refined_embedding\n",
        "\n",
        "    sims = cosine_similarity(user_vec, filtered_embeddings)[0]\n",
        "    top_indices = sims.argsort()[::-1][:top_n]\n",
        "    recommendations = [(filtered_names[i], sims[i]) for i in top_indices]\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "2ElHRPRVzFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Example usage: Getting recommendations after tuning and training\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"hotel dengan kolam renang\"\n",
        "    location = \"Kota Malang\"\n",
        "\n",
        "    print(f\"Rekomendasi hotel di {location} untuk prompt '{user_prompt}':\")\n",
        "    recs = recommend_hotels(user_prompt, location)\n",
        "    for name, score in recs:\n",
        "        print(f\"- {name}: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGijdQYzQtC",
        "outputId": "6672283a-e79b-4a2e-af92-6d7dee7ee704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi hotel di Kota Malang untuk prompt 'hotel dengan kolam renang':\n",
            "- Front One Budget Malang by Azana: 0.6831\n",
            "- The Alana Hotel Malang: 0.6426\n",
            "- Sans Hotel La Vida Malang: 0.6183\n",
            "- Sweet Garden Boutique Guest House: 0.5581\n",
            "- Atria Hotel Malang: 0.5085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek nilai unik pada kolom Lokasi\n",
        "print(df['Lokasi'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBIZsH1T3aIE",
        "outputId": "38406faa-779a-4ba4-f822-bd02607e4d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Banyuwangi' 'Mojopanggung' nan 'Blitar' 'Jember' 'Kota Kediri' 'Ngasem'\n",
            " 'Mojoroto' 'Sidoharjo' 'Lamongan' 'Rejosari' 'Plosowahyu'\n",
            " 'Tumenggung Baru' 'Banaran' 'Paciran' 'Kota Madiun' 'Kaibon'\n",
            " 'Kota Malang' 'Surabaya' 'Kota Batu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Periksa hotel yang digabung menjadi \"Other\"\n",
        "print(df[df['Name'] == 'Other'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWG1wk8z3aZd",
        "outputId": "908430d9-e989-4f16-8df6-84dbd3dc0f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Name, Description, Lokasi]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7SL4Y2t3cQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}