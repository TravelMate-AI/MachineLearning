{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OtMqeMVj491",
        "outputId": "963c32bb-8e97-4438-84da-2cba4413cb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, TFAutoModel"
      ],
      "metadata": {
        "id": "HuU_n_TMkLMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data_restoran.csv\")\n",
        "df['Description'] = df['Description'].str.lower()\n",
        "print(\"Dataset info:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ddbYv4-kM2q",
        "outputId": "84e2e6ba-4436-417c-f8a0-d574ec368da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 67 entries, 0 to 66\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Name         67 non-null     object\n",
            " 1   Description  67 non-null     object\n",
            " 2   Categories   67 non-null     object\n",
            " 3   Lokasi       67 non-null     object\n",
            "dtypes: object(4)\n",
            "memory usage: 2.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Prepare tokenizer and pretrained IndoBERT model (TensorFlow)\n",
        "model_name = \"indobenchmark/indobert-base-p2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = TFAutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iovhamrUkSUv",
        "outputId": "ad93a3d0-94c3-4231-c52b-1d8172ead3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some layers from the model checkpoint at indobenchmark/indobert-base-p2 were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at indobenchmark/indobert-base-p2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Generate embeddings from text - returns numpy array (1, hidden_size)\n",
        "def get_bert_embeddings(texts):\n",
        "    # texts: list of strings or single string\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    inputs = tokenizer(texts, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
        "    outputs = bert_model(inputs)\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "    return embeddings.numpy()"
      ],
      "metadata": {
        "id": "NRaYvtyEkUCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prepare Training Data for Keras model\n",
        "# Generate embeddings for all restoran descriptions\n",
        "hotel_desc_embeddings = get_bert_embeddings(df['Description'].tolist())\n",
        "\n",
        "# Encode restaurant names as class labels for classification task\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(df['Name'])\n",
        "\n",
        "# Re-encode labels after combining rare classes\n",
        "#labels = label_encoder.fit_transform(df['Name'])\n",
        "\n",
        "# Generate embeddings again after modifying the dataset\n",
        "restoran_desc_embeddings = get_bert_embeddings(df['Description'].tolist())\n",
        "\n",
        "# Split into train and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(hotel_desc_embeddings, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "NRVZY-VdkWoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Build tunable keras model function for hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    inputs = tf.keras.Input(shape=(restoran_desc_embeddings.shape[1],))\n",
        "    x = inputs\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        units = hp.Int(f'units_{i}', min_value=64, max_value=512, step=64)\n",
        "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
        "        dropout_rate = hp.Float(f'dropout_{i}', 0.1, 0.5, step=0.1)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZQz2ZmQ0kaWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='kt_tuner_dir',\n",
        "    project_name='restoran_nlp_recommendation'\n",
        ")\n",
        "#eraly stop\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "print(\"Starting hyperparameter search...\")\n",
        "tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[stop_early])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(f\"Number of layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Layer {i} units: {best_hps.get(f'units_{i}')}, dropout: {best_hps.get(f'dropout_{i}')}\")\n",
        "\n",
        "print(f\"Learning rate: {best_hps.get('learning_rate')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-LiM8q4kgzz",
        "outputId": "a8278157-4afa-4adc-b602-09416e57f875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from kt_tuner_dir/restoran_nlp_recommendation/tuner0.json\n",
            "Starting hyperparameter search...\n",
            "Best hyperparameters found:\n",
            "Number of layers: 3\n",
            "Layer 0 units: 128, dropout: 0.30000000000000004\n",
            "Layer 1 units: 256, dropout: 0.2\n",
            "Layer 2 units: 128, dropout: 0.4\n",
            "Learning rate: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Build the best model and train fully\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[stop_early]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba0FZDeskj2z",
        "outputId": "3acfb653-e49c-4f08-c5f2-1e1196a41678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 0.0394 - loss: 4.8001 - val_accuracy: 0.0000e+00 - val_loss: 4.2905\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0000e+00 - loss: 4.6552 - val_accuracy: 0.0000e+00 - val_loss: 4.2836\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0145 - loss: 4.6053 - val_accuracy: 0.0000e+00 - val_loss: 4.2791\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.0145 - loss: 4.4710 - val_accuracy: 0.0476 - val_loss: 4.2729\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.0000e+00 - loss: 4.5469 - val_accuracy: 0.0476 - val_loss: 4.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.0249 - loss: 4.5453 - val_accuracy: 0.0476 - val_loss: 4.2651\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.0145 - loss: 4.4137 - val_accuracy: 0.0476 - val_loss: 4.2645\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0000e+00 - loss: 4.2467 - val_accuracy: 0.0476 - val_loss: 4.2660\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.0000e+00 - loss: 4.4372 - val_accuracy: 0.0476 - val_loss: 4.2698\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.0249 - loss: 4.3625 - val_accuracy: 0.0476 - val_loss: 4.2741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Helper function to recommend hotels based on similarity of embeddings refined by trained Keras model\n",
        "def recommend_hotels(user_prompt, location, top_n=5):\n",
        "    user_embedding = get_bert_embeddings(user_prompt)\n",
        "    intermediate_layer_model = tf.keras.Model(\n",
        "        inputs=model.input,\n",
        "        outputs=model.layers[-2].output\n",
        "    )\n",
        "    user_refined_embedding = intermediate_layer_model(user_embedding).numpy()\n",
        "\n",
        "    filtered_df = df[df['Lokasi'].str.lower() == location.lower()]\n",
        "    filtered_embeddings = []\n",
        "    filtered_names = []\n",
        "    for idx, row in filtered_df.iterrows():\n",
        "        emb = hotel_desc_embeddings[idx:idx+1]\n",
        "        refined_emb = intermediate_layer_model(emb).numpy()\n",
        "        filtered_embeddings.append(refined_emb[0])\n",
        "        filtered_names.append(row['Name'])\n",
        "\n",
        "    filtered_embeddings = np.array(filtered_embeddings)\n",
        "    user_vec = user_refined_embedding\n",
        "\n",
        "    sims = cosine_similarity(user_vec, filtered_embeddings)[0]\n",
        "    top_indices = sims.argsort()[::-1][:top_n]\n",
        "    recommendations = [(filtered_names[i], sims[i]) for i in top_indices]\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "nSKF0twAkoYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Example usage: Getting recommendations after tuning and training\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"makanan dengan harga terjangkau\"\n",
        "    location = \"Kota Malang\"\n",
        "\n",
        "    print(f\"Rekomendasi makanan di {location} untuk prompt '{user_prompt}':\")\n",
        "    recs = recommend_hotels(user_prompt, location)\n",
        "    for name, score in recs:\n",
        "        print(f\"- {name}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd2Mwc61kq6V",
        "outputId": "bd3bac9a-e424-432a-9a91-737f3bba2a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi makanan di Kota Malang untuk prompt 'makanan dengan harga terjangkau':\n",
            "- Depot Gang Djangkrik Kawi Atas Malang: 0.8672\n",
            "- Ayam Goreng Tenes: 0.8073\n",
            "- Rumah Makan Kertanegara: 0.7753\n",
            "- Gang Djangkrik Restaurant: 0.7441\n",
            "- signora pasta malang: 0.7438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model dalam format SavedModel\n",
        "model.export(\"restoran_model_tfjs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BmmoMQfWdk8",
        "outputId": "9e766444-3dde-4539-b819-e26dd7373e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'restoran_model_tfjs'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 768), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 67), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137028470830480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028470832016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028470831824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028461216400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028461217744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028461218896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028461218512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137028461220048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPfRz8qIXCqb",
        "outputId": "8e25c85e-e9a8-4765-c307-edd21e1851b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.11/dist-packages (4.22.0)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.10.6)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (6.5.2)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.1)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (23.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (2.0.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.11.13)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (4.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (1.15.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.13.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.1)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.19.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.89)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (1.12.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2025.3.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.22.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=tf_saved_model \\\n",
        "    --output_format=tfjs_graph_model \\\n",
        "    restoran_model_tfjs restoran_model_tfjs_web"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4oP_TbZXSgq",
        "outputId": "067f16fc-005f-458a-a8e4-e91fff4d179f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-12 13:38:40.579542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749735520.629629   22226 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749735520.637406   22226 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
            "2025-06-12 13:38:46.759910: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "I0000 00:00:1749735526.881408   22226 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1749735526.881615   22226 single_machine.cc:361] Starting new session\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/restoran_model_tfjs.zip /content/restoran_model_tfjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvbM8bp8Xn6l",
        "outputId": "5e422b93-c402-4d28-ee96-0c7490b337da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/restoran_model_tfjs/ (stored 0%)\n",
            "  adding: content/restoran_model_tfjs/fingerprint.pb (stored 0%)\n",
            "  adding: content/restoran_model_tfjs/variables/ (stored 0%)\n",
            "  adding: content/restoran_model_tfjs/variables/variables.index (deflated 62%)\n",
            "  adding: content/restoran_model_tfjs/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/restoran_model_tfjs/saved_model.pb (deflated 85%)\n",
            "  adding: content/restoran_model_tfjs/assets/ (stored 0%)\n"
          ]
        }
      ]
    }
  ]
}