{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os"
      ],
      "metadata": {
        "id": "NvvS9c5nwjep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFSentenceTransformer(tf.keras.Model):\n",
        "    def __init__(self, base_model, tokenizer):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.base_model = base_model\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_name):\n",
        "        \"\"\"Memuat model dan tokenizer dari Hugging Face Hub.\"\"\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        base_model = TFAutoModel.from_pretrained(model_name)\n",
        "        return cls(base_model, tokenizer)\n",
        "\n",
        "    @classmethod\n",
        "    def from_local(cls, model_path):\n",
        "        \"\"\"Memuat model dan tokenizer dari direktori lokal.\"\"\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "        base_model = TFAutoModel.from_pretrained(model_path, local_files_only=True)\n",
        "        return cls(base_model, tokenizer)\n",
        "\n",
        "    def save(self, save_path):\n",
        "        \"\"\"Menyimpan base_model dan tokenizer ke direktori.\"\"\"\n",
        "        self.base_model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\"Model disimpan di: {save_path}\")\n",
        "\n",
        "    # Fungsi lainnya tetap sama\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state\n",
        "        input_mask_expanded = tf.cast(tf.expand_dims(attention_mask, -1), tf.float32)\n",
        "        return tf.reduce_sum(token_embeddings * input_mask_expanded, axis=1) / tf.maximum(\n",
        "            tf.reduce_sum(input_mask_expanded, axis=1), 1e-9\n",
        "        )\n",
        "\n",
        "    def encode(self, sentences):\n",
        "        encoded = self.tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "        # Tidak perlu GradientTape untuk inferensi/encoding\n",
        "        model_output = self.base_model(\n",
        "            input_ids=encoded['input_ids'],\n",
        "            attention_mask=encoded['attention_mask'],\n",
        "            training=False # Set ke False untuk inferensi\n",
        "        )\n",
        "        sentence_embeddings = self.mean_pooling(model_output, encoded['attention_mask'])\n",
        "        sentence_embeddings = tf.nn.l2_normalize(sentence_embeddings, axis=1)\n",
        "        return sentence_embeddings.numpy()"
      ],
      "metadata": {
        "id": "z6_fbc8L4aXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TravelRecommendationChatbot:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.travel_data = None\n",
        "        self.location_embeddings = None\n",
        "\n",
        "    # Fungsi lainnya sebagian besar sama, hanya referensinya yang disesuaikan\n",
        "    def load_travel_data(self, csv_path):\n",
        "        print(\"Loading travel data...\")\n",
        "        self.travel_data = pd.read_csv(csv_path).dropna().reset_index(drop=True) # Tambah reset_index\n",
        "        self.travel_data['combined_text'] = (\n",
        "            self.travel_data['Name'] + \". \" +\n",
        "            self.travel_data['Description'] + \". \" +\n",
        "            self.travel_data['Categories'] + \". \" +\n",
        "            self.travel_data['Lokasi']\n",
        "        )\n",
        "        print(f\"Loaded {len(self.travel_data)} travel locations\")\n",
        "\n",
        "    def generate_embeddings(self, batch_size=16):\n",
        "        print(\"Generating embeddings for travel locations...\")\n",
        "        combined_texts = self.travel_data['combined_text'].tolist()\n",
        "        self.location_embeddings = self.model.encode(combined_texts)\n",
        "        print(\"Embeddings generated successfully!\")\n",
        "\n",
        "    # ... (get_recommendations, format_response, chat, dll. tetap sama)\n",
        "    def get_recommendations(self, query, top_n=5):\n",
        "        processed_query = query.lower().strip()\n",
        "        query_embedding = self.model.encode([processed_query])\n",
        "        similarities = cosine_similarity(query_embedding, self.location_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "        return [{\n",
        "            'name': self.travel_data.iloc[idx]['Name'],\n",
        "            'description': self.travel_data.iloc[idx]['Description'],\n",
        "            'category': self.travel_data.iloc[idx]['Categories'],\n",
        "            'location': self.travel_data.iloc[idx]['Lokasi'],\n",
        "            'similarity_score': similarities[idx]\n",
        "        } for idx in top_indices]\n",
        "\n",
        "    def format_response(self, recommendations):\n",
        "        if not recommendations:\n",
        "            return \"Maaf, saya tidak menemukan rekomendasi yang sesuai.\"\n",
        "        response = \"Berikut rekomendasi tempat wisata:\\n\\n\"\n",
        "        for i, rec in enumerate(recommendations, 1):\n",
        "            desc = rec['description'][:200] + ('...' if len(rec['description']) > 200 else '')\n",
        "            response += (\n",
        "                f\"{i}. **{rec['name']}** ({rec['location']})\\n\"\n",
        "                f\"   Kategori: {rec['category']}\\n\"\n",
        "                f\"   {desc}\\n\"\n",
        "                f\"   Skor Kesesuaian: {rec['similarity_score']:.3f}\\n\\n\"\n",
        "            )\n",
        "        return response\n",
        "\n",
        "    def chat(self, user_input):\n",
        "        try:\n",
        "            recommendations = self.get_recommendations(user_input)\n",
        "            return self.format_response(recommendations)\n",
        "        except Exception as e:\n",
        "            return f\"Terjadi kesalahan: {str(e)}\""
      ],
      "metadata": {
        "id": "jGUK7_kt4cln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(model, training_data, epochs=3):\n",
        "    print(\"Fine-tuning model...\")\n",
        "    queries, locations, scores = zip(*training_data)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        # ... (Looping fine-tuning sama persis) ...\n",
        "        for i in range(0, len(queries), 8):\n",
        "            batch_q = list(queries[i:i+8])\n",
        "            batch_l = list(locations[i:i+8])\n",
        "            batch_s = tf.constant(scores[i:i+8], dtype=tf.float32)\n",
        "\n",
        "            q_inputs = model.tokenizer(batch_q, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "            l_inputs = model.tokenizer(batch_l, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                q_emb = model.mean_pooling(model.base_model(**q_inputs), q_inputs['attention_mask'])\n",
        "                l_emb = model.mean_pooling(model.base_model(**l_inputs), l_inputs['attention_mask'])\n",
        "                q_emb = tf.nn.l2_normalize(q_emb, axis=1)\n",
        "                l_emb = tf.nn.l2_normalize(l_emb, axis=1)\n",
        "                similarity = tf.reduce_sum(q_emb * l_emb, axis=1)\n",
        "                loss = loss_fn(batch_s, similarity)\n",
        "\n",
        "            grads = tape.gradient(loss, model.base_model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.base_model.trainable_variables))\n",
        "            print(f\"Batch {i//8 + 1}, Loss: {loss.numpy():.4f}\")\n",
        "    print(\"Fine-tuning completed.\")\n"
      ],
      "metadata": {
        "id": "46-T_xh44eOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_save_model():\n",
        "    print(\"--- Memulai Sesi Pelatihan ---\")\n",
        "\n",
        "    # 1. Muat model dasar dari Hugging Face\n",
        "    base_model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "    model = TFSentenceTransformer.from_pretrained(base_model_name)\n",
        "\n",
        "    # 2. Muat data untuk digunakan dalam fine-tuning\n",
        "    temp_data = pd.read_csv(\"cleaned_data_wisata.csv\").dropna().reset_index()\n",
        "    temp_data['combined_text'] = (\n",
        "        temp_data['Name'] + \". \" +\n",
        "        temp_data['Description'] + \". \" +\n",
        "        temp_data['Categories'] + \". \" +\n",
        "        temp_data['Lokasi']\n",
        "    )\n",
        "    training_data = [\n",
        "        (\"tempat wisata yang sejuk dan alami\", temp_data['combined_text'][0], 0.95),\n",
        "        (\"pantai yang indah dan bersih\", temp_data['combined_text'][1], 0.92),\n",
        "        (\"tempat bersejarah dan edukatif\", temp_data['combined_text'][2], 0.89),\n",
        "        (\"wisata religi menarik\", temp_data['combined_text'][3], 0.93),\n",
        "        (\"air terjun yang menyejukkan\", temp_data['combined_text'][4], 0.94)\n",
        "    ]\n",
        "\n",
        "    # 3. Lakukan fine-tuning\n",
        "    fine_tune_model(model, training_data, epochs=5)\n",
        "\n",
        "    # ‚úÖ 4. Simpan model dan tokenizer\n",
        "    fine_tuned_path = \"./fine_tuned_model\"\n",
        "    model.save(fine_tuned_path)\n",
        "    print(\"--- Sesi Pelatihan Selesai ---\")\n",
        "    return fine_tuned_path"
      ],
      "metadata": {
        "id": "t1YQKUTX4f_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot_from_local(model_path):\n",
        "    print(\"\\n--- Memulai Sesi Chatbot (Inferensi) ---\")\n",
        "\n",
        "    # 1. Muat model yang sudah di-fine-tune DARI DISK menggunakan custom class\n",
        "    print(f\"Memuat model dari: {model_path}\")\n",
        "    # Gunakan TFSentenceTransformer.from_local() untuk memuat model dan tokenizer\n",
        "    model = TFSentenceTransformer.from_local(model_path)\n",
        "\n",
        "    # 2. Inisialisasi chatbot dengan model yang sudah dimuat\n",
        "    chatbot = TravelRecommendationChatbot(model)\n",
        "\n",
        "    # 3. Muat data wisata dan generate embeddings\n",
        "    chatbot.load_travel_data(\"cleaned_data_wisata.csv\")\n",
        "    chatbot.generate_embeddings()\n",
        "\n",
        "    # 4. Jalankan mode interaktif\n",
        "    print(\"\\nüèùÔ∏è Travel Chatbot Siap! (Ketik 'keluar' untuk berhenti)\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"Anda: \")\n",
        "        if user_input.lower() in ['keluar', 'exit', 'quit']:\n",
        "            print(\"Terima kasih! Sampai jumpa üå¥\")\n",
        "            break\n",
        "        print(\"\\nChatbot:\", chatbot.chat(user_input))\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "6OpJp6JqD03s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_path = train_and_save_model()\n",
        "run_chatbot_from_local(fine_tuned_model_path)"
      ],
      "metadata": {
        "id": "0ohmE3_j4jm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62ce3906-bd85-4db4-9177-855f13c2bef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Memulai Sesi Pelatihan ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning model...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1, Loss: 0.3975\n",
            "Epoch 2/5\n",
            "Batch 1, Loss: 0.2335\n",
            "Epoch 3/5\n",
            "Batch 1, Loss: 0.1298\n",
            "Epoch 4/5\n",
            "Batch 1, Loss: 0.0721\n",
            "Epoch 5/5\n",
            "Batch 1, Loss: 0.0358\n",
            "Fine-tuning completed.\n",
            "Model disimpan di: ./fine_tuned_model\n",
            "--- Sesi Pelatihan Selesai ---\n",
            "\n",
            "--- Memulai Sesi Chatbot (Inferensi) ---\n",
            "Memuat model dari: ./fine_tuned_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at ./fine_tuned_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading travel data...\n",
            "Loaded 50 travel locations\n",
            "Generating embeddings for travel locations...\n",
            "Embeddings generated successfully!\n",
            "\n",
            "üèùÔ∏è Travel Chatbot Siap! (Ketik 'keluar' untuk berhenti)\n",
            "\n",
            "Anda: rekomendasi tempat wisata gunung\n",
            "\n",
            "Chatbot: Berikut rekomendasi tempat wisata:\n",
            "\n",
            "1. **Kawah Ijen** (Banyuwangi)\n",
            "   Kategori: Alam\n",
            "   Kawah Ijen terkenal dengan fenomena \"blue fire\"-nya yang langka dan danau asam berwarna toska yang menakjubkan. Pendakian malam menjadi favorit bagi para petualang. Terletak di perbatasan Banyuwangi d...\n",
            "   Skor Kesesuaian: 0.818\n",
            "\n",
            "2. **Coban Rondo** (Kabupaten Malang)\n",
            "   Kategori: Air Terjun\n",
            "   Air terjun alami yang mudah diakses dengan pemandangan tropis yang asri dan menenangkan. Terletak di kawasan Pujon, air terjun ini dilengkapi dengan area duduk dan bangku yang nyaman, cocok untuk pikn...\n",
            "   Skor Kesesuaian: 0.780\n",
            "\n",
            "3. **Coban Pelangi** (Gubukklakah)\n",
            "   Kategori: Air Terjun\n",
            "   Air terjun besar yang dapat dicapai dengan jalur hiking melalui hutan yang rindang dan suasana yang tenang. Terletak di kawasan pegunungan, Coban Pelangi terkenal dengan keindahan air terjunnya yang m...\n",
            "   Skor Kesesuaian: 0.758\n",
            "\n",
            "4. **Omah Kayu** (Kota Batu)\n",
            "   Kategori: Alam\n",
            "   Penginapan unik berupa rumah kayu yang dibangun di atas pohon dengan pemandangan pegunungan yang indah dan suasana hutan yang tenang. Terletak di kawasan wisata Selecta, Omah Kayu menawarkan pengalama...\n",
            "   Skor Kesesuaian: 0.749\n",
            "\n",
            "5. **De Tjangkul** (Kota Batu)\n",
            "   Kategori: Alam\n",
            "   Destinasi wisata keluarga di Kota Batu yang memadukan konsep pertanian dan taman foto bertema Belanda. Dibuka sejak 2018, tempat ini menawarkan berbagai spot foto unik seperti rumah terbalik, kincir a...\n",
            "   Skor Kesesuaian: 0.730\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Anda: rekoemndasi temapt wisata memetik buah\n",
            "\n",
            "Chatbot: Berikut rekomendasi tempat wisata:\n",
            "\n",
            "1. **De Tjangkul** (Kota Batu)\n",
            "   Kategori: Alam\n",
            "   Destinasi wisata keluarga di Kota Batu yang memadukan konsep pertanian dan taman foto bertema Belanda. Dibuka sejak 2018, tempat ini menawarkan berbagai spot foto unik seperti rumah terbalik, kincir a...\n",
            "   Skor Kesesuaian: 0.756\n",
            "\n",
            "2. **Sekartaji Park** (Kota Kediri)\n",
            "   Kategori: Taman Hiburan\n",
            "   Taman kota yang kompak dengan vegetasi tropis yang rimbun, menghadirkan suasana sejuk dan asri di tengah keramaian kota. Taman ini dilengkapi dengan kolam bunga teratai yang dihuni ikan koi, menambah ...\n",
            "   Skor Kesesuaian: 0.751\n",
            "\n",
            "3. **Agrowisata Belimbing Karangsari** (Blitar)\n",
            "   Kategori: Edukatif\n",
            "   Perkebunan luas yang menampilkan pohon belimbing segar yang dapat dipetik langsung oleh pengunjung dan dinikmati di tempat. Terletak di kawasan Karangsari, tempat ini menawarkan pengalaman wisata eduk...\n",
            "   Skor Kesesuaian: 0.742\n",
            "\n",
            "4. **Eco Active Park** (Kota Batu)\n",
            "   Kategori: Taman Hiburan\n",
            "   empat wisata yang terkenal dengan ikon rumah terbalik yang unik dan menjadi spot foto favorit pengunjung. Selain menikmati keunikan arsitektur tersebut, pengunjung juga dapat menjelajahi berbagai waha...\n",
            "   Skor Kesesuaian: 0.742\n",
            "\n",
            "5. **Omah Kayu** (Kota Batu)\n",
            "   Kategori: Alam\n",
            "   Penginapan unik berupa rumah kayu yang dibangun di atas pohon dengan pemandangan pegunungan yang indah dan suasana hutan yang tenang. Terletak di kawasan wisata Selecta, Omah Kayu menawarkan pengalama...\n",
            "   Skor Kesesuaian: 0.732\n",
            "\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1672367949>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfine_tuned_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_chatbot_from_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tuned_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-1993874686>\u001b[0m in \u001b[0;36mrun_chatbot_from_local\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüèùÔ∏è Travel Chatbot Siap! (Ketik 'keluar' untuk berhenti)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anda: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'keluar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Terima kasih! Sampai jumpa üå¥\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}